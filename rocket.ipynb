{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from main import *\n",
    "\n",
    "\n",
    "# StratifiedCrossValidation\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "\n",
    "from sktime.transformations.panel.rocket import MiniRocketMultivariate\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.metrics import f1_score, recall_score, confusion_matrix, ConfusionMatrixDisplay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "machines = [\"M01\", \"M02\",\"M03\"]\n",
    "process_names = [\"OP00\",\"OP01\",\"OP02\",\"OP03\",\"OP04\",\"OP05\",\"OP06\",\"OP07\",\"OP08\",\"OP09\",\"OP10\",\"OP11\",\"OP12\",\"OP13\",\"OP14\"]\n",
    "labels = [\"good\",\"bad\"]\n",
    "path_to_dataset = Path(\"./data/\").absolute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_data = []\n",
    "y_data = []\n",
    "\n",
    "for process_name, machine, label in itertools.product(process_names, machines, labels):\n",
    "    data_path = os.path.join(path_to_dataset, machine, process_name, label)\n",
    "    data_list, data_label = data_loader_utils.load_tool_research_data(data_path, label=label, add_additional_label = True, verbose = False)\n",
    "    #concatenating\n",
    "    X_data.extend(data_list)\n",
    "    y_data.extend(data_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = [x.astype(np.float64) for x in X_data] # Ensure all examples have the same datatype\n",
    "X = np.array([x[:4096, :3] for x in X]) # Select the first 4096 timesteps of all three dimensions for each row\n",
    "y = np.array([0 if id.split(\"_\")[-1] == \"good\" else 1 for id in y_data])\n",
    "\n",
    "# Reshape X into a dataframe that is compatible with MiniRocket transform\n",
    "axis = [\"X-axis\", \"Y-axis\", \"Z-axis\"] \n",
    "axisdict = {\"X-axis\": [], \"Y-axis\":[],  \"Z-axis\":[]}\n",
    "for i, ax in enumerate(axis):\n",
    "    for n in range(X.shape[0]):\n",
    "        axisdict[ax].append(pd.Series(X[n][:,i]))\n",
    "\n",
    "X_df = pd.DataFrame(axisdict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [y.split(\"_\") for y in y_data]\n",
    "y_df = pd.DataFrame(a)\n",
    "df = X_df.join(y_df).rename(columns = {0: \"MC\", 1: \"MM\", 2: \"YY\", 3: \"OP\", 4: \"n\", 5: \"y\"})\n",
    "df[\"y\"] = df[\"y\"].apply(lambda x: 1 if x == \"bad\" else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "M01 = df[df[\"MC\"] == \"M01\"]\n",
    "X_M01, y_M01 = M01.iloc[:,0:3], M01.iloc[:,-1]\n",
    "\n",
    "M02 = df[df[\"MC\"] == \"M02\"]\n",
    "X_M02, y_M02 = M02.iloc[:,0:3], M02.iloc[:,-1]\n",
    "\n",
    "M03 = df[df[\"MC\"] == \"M03\"]\n",
    "X_M03, y_M03 = M03.iloc[:,0:3], M03.iloc[:,-1]\n",
    "\n",
    "\n",
    "F1_machine = []\n",
    "Recall_machine = []\n",
    "\n",
    "for i in range(3):\n",
    "    X_M01_train, X_M01_test, y_M01_train, y_M01_test = train_test_split(X_M01, y_M01, test_size = 0.9, stratify = y_M01)\n",
    "    \n",
    "    X_M02_train, X_M02_test, y_M02_train, y_M02_test = train_test_split(X_M02, y_M02, test_size = 0.9, stratify = y_M02)\n",
    "    \n",
    "    X_train = pd.concat((X_M01_train, X_M02_train))\n",
    "    y_train = pd.concat((y_M01_train, y_M02_train))\n",
    "    \n",
    "    X_test = pd.concat((X_M01_test, X_M02_test, X_M03))\n",
    "    y_test = pd.concat((y_M01_test, y_M02_test, y_M03))\n",
    "    \n",
    "    trf = MiniRocketMultivariate(n_jobs = -1) \n",
    "    trf.fit(X_train)\n",
    "    X_train_trf = trf.transform(X_train)\n",
    "    X_test_trf = trf.transform(X_test) \n",
    "    \n",
    "    clf = LogisticRegression()\n",
    "    \n",
    "    clf.fit(X_train_trf, y_train)\n",
    "    y_pred = clf.predict(X_test_trf)\n",
    "\n",
    "    F1_machine.append(f1_score(y_test, y_pred))\n",
    "    Recall_machine.append(recall_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "Feb_2019 = df[(df[\"MM\"] == \"Feb\") & (df[\"YY\"] == \"2019\")]\n",
    "Aug_2019 = df[(df[\"MM\"] == \"Aug\") & (df[\"YY\"] == \"2019\")]\n",
    "Feb_2020 = df[(df[\"MM\"] == \"Feb\") & (df[\"YY\"] == \"2020\")]\n",
    "Aug_2020 = df[(df[\"MM\"] == \"Aug\") & (df[\"YY\"] == \"2020\")]\n",
    "Feb_2021 = df[(df[\"MM\"] == \"Feb\") & (df[\"YY\"] == \"2021\")]\n",
    "Aug_2021 = df[(df[\"MM\"] == \"Aug\") & (df[\"YY\"] == \"2021\")]\n",
    "\n",
    "X_Feb_2019, y_Feb_2019 = Feb_2019.iloc[:,0:3], Feb_2019.iloc[:,-1]\n",
    "X_Aug_2019, y_Aug_2019 = Aug_2019.iloc[:,0:3], Aug_2019.iloc[:,-1]\n",
    "X_Feb_2020, y_Feb_2020 = Feb_2020.iloc[:,0:3], Feb_2020.iloc[:,-1]\n",
    "X_Aug_2020, y_Aug_2020 = Aug_2020.iloc[:,0:3], Aug_2020.iloc[:,-1]\n",
    "X_Feb_2021, y_Feb_2021 = Feb_2021.iloc[:,0:3], Feb_2021.iloc[:,-1]\n",
    "X_Aug_2021, y_Aug_2021 = Aug_2021.iloc[:,0:3], Aug_2021.iloc[:,-1]\n",
    "\n",
    "F1_time = []\n",
    "Recall_time = []\n",
    "\n",
    "for i in range(3):\n",
    "    X_Feb_2019_train, X_Feb_2019_test, y_Feb_2019_train, y_Feb_2019_test = train_test_split(X_Feb_2019, y_Feb_2019, test_size = 0.9, stratify = y_Feb_2019)\n",
    "        \n",
    "    X_Aug_2019_train, X_Aug_2019_test, y_Aug_2019_train, y_Aug_2019_test = train_test_split(X_Aug_2019, y_Aug_2019, test_size = 0.9, stratify = y_Aug_2019)\n",
    "\n",
    "    X_Feb_2020_train, X_Feb_2020_test, y_Feb_2020_train, y_Feb_2020_test = train_test_split(X_Feb_2020, y_Feb_2020, test_size = 0.9, stratify = y_Feb_2020)\n",
    "    \n",
    "    X_Feb_2021_train, X_Feb_2021_test, y_Feb_2021_train, y_Feb_2021_test = train_test_split(X_Feb_2021, y_Feb_2021, test_size = 0.9, stratify = y_Feb_2021)\n",
    "\n",
    "    X_train = pd.concat((X_Feb_2019_train, X_Aug_2019_train, X_Feb_2020_train, X_Feb_2021_train))\n",
    "    X_test = pd.concat((X_Feb_2019_test, X_Aug_2019_test, X_Feb_2020_test, X_Aug_2020, X_Feb_2021_test, X_Aug_2021))\n",
    "    \n",
    "    y_train = pd.concat((y_Feb_2019_train, y_Aug_2019_train, y_Feb_2020_train, y_Feb_2021_train))\n",
    "    y_test = pd.concat((y_Feb_2019_test, y_Aug_2019_test, y_Feb_2020_test, y_Aug_2020, y_Feb_2021_test, y_Aug_2021))\n",
    "    \n",
    "    trf = MiniRocketMultivariate(n_jobs = -1) \n",
    "    trf.fit(X_train)\n",
    "    X_train_trf = trf.transform(X_train)\n",
    "    X_test_trf = trf.transform(X_test) \n",
    "    \n",
    "    clf = LogisticRegression()\n",
    "    \n",
    "    clf.fit(X_train_trf, y_train)\n",
    "    y_pred = clf.predict(X_test_trf)\n",
    "    \n",
    "    F1_time.append(f1_score(y_test, y_pred))\n",
    "    Recall_time.append(recall_score(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "OP07 = df[df[\"OP\"] == \"OP07\"]\n",
    "OP01 = df[df[\"OP\"] == \"OP01\"]\n",
    "OP02 = df[df[\"OP\"] == \"OP02\"]\n",
    "OP10 = df[df[\"OP\"] == \"OP10\"]\n",
    "OP04 = df[df[\"OP\"] == \"OP04\"]\n",
    "OP = df[~df[\"OP\"].isin([\"OP07\", \"OP01\", \"OP02\", \"OP10\", \"OP04\"])]\n",
    "\n",
    "X_OP07, y_OP07 = OP07.iloc[:,0:3], OP07.iloc[:,-1]\n",
    "X_OP01, y_OP01 = OP01.iloc[:,0:3], OP01.iloc[:,-1]\n",
    "X_OP02, y_OP02 = OP02.iloc[:,0:3], OP02.iloc[:,-1]\n",
    "X_OP10, y_OP10 = OP10.iloc[:,0:3], OP10.iloc[:,-1]\n",
    "X_OP04, y_OP04 = OP04.iloc[:,0:3], OP04.iloc[:,-1]\n",
    "X_OP, y_OP = OP.iloc[:,0:3], OP.iloc[:,-1]\n",
    "\n",
    "F1_OP = []\n",
    "Recall_OP = []\n",
    "\n",
    "for i in range(3):\n",
    "    X_OP07_train, X_OP07_test, y_OP07_train, y_OP07_test = train_test_split(X_OP07, y_OP07, test_size = 0.8, stratify = y_OP07)\n",
    "    \n",
    "    X_OP01_train, X_OP01_test, y_OP01_train, y_OP01_test = train_test_split(X_OP01, y_OP01, test_size = 0.8, stratify = y_OP01)\n",
    "    \n",
    "    X_OP02_train, X_OP02_test, y_OP02_train, y_OP02_test = train_test_split(X_OP02, y_OP02, test_size = 0.8, stratify = y_OP02)\n",
    "    \n",
    "    X_OP10_train, X_OP10_test, y_OP10_train, y_OP10_test = train_test_split(X_OP10, y_OP10, test_size = 0.8, stratify = y_OP10)\n",
    "    \n",
    "    X_OP04_train, X_OP04_test, y_OP04_train, y_OP04_test = train_test_split(X_OP04, y_OP04, test_size = 0.8, stratify = y_OP04)\n",
    "    \n",
    "    X_train = pd.concat((X_OP07_train, X_OP01_train, X_OP02_train, X_OP10_train, X_OP04_train))\n",
    "    X_test = pd.concat((X_OP07_test, X_OP01_test, X_OP02_test, X_OP10_test, X_OP04_test, X_OP))\n",
    "    \n",
    "    y_train = pd.concat((y_OP07_train, y_OP01_train, y_OP02_train, y_OP10_train, y_OP04_train))\n",
    "    y_test = pd.concat((y_OP07_test, y_OP01_test, y_OP02_test, y_OP10_test, y_OP04_test, y_OP))\n",
    "    \n",
    "    \n",
    "    trf = MiniRocketMultivariate(n_jobs = -1) \n",
    "    trf.fit(X_train)\n",
    "    X_train_trf = trf.transform(X_train)\n",
    "    X_test_trf = trf.transform(X_test) \n",
    "    \n",
    "    clf = LogisticRegression()\n",
    "    \n",
    "    clf.fit(X_train_trf, y_train)\n",
    "    y_pred = clf.predict(X_test_trf)\n",
    "\n",
    "    F1_OP.append(f1_score(y_test, y_pred))\n",
    "    Recall_OP.append(recall_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Machine Wise\n",
      "0.973499280331894\n",
      "Recall Machine Wise\n",
      "0.9583333333333334\n",
      "F1 Time Wise\n",
      "0.9841269841269841\n",
      "Recall Time Wise\n",
      "0.96875\n",
      "F1 OP Wise\n",
      "0.9789570567244986\n",
      "Recall OP Wise\n",
      "0.96875\n"
     ]
    }
   ],
   "source": [
    "print(\"F1 Machine Wise\")\n",
    "print(np.mean(F1_machine))\n",
    "print(\"Recall Machine Wise\")\n",
    "print(np.mean(Recall_machine))\n",
    "print(\"F1 Time Wise\")\n",
    "print(np.mean(F1_time))\n",
    "print(\"Recall Time Wise\")\n",
    "print(np.mean(Recall_time))\n",
    "print(\"F1 OP Wise\")\n",
    "print(np.mean(F1_OP))\n",
    "print(\"Recall OP Wise\")\n",
    "print(np.mean(Recall_OP))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
