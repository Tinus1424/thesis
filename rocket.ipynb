{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from main import *\n",
    "import time\n",
    "\n",
    "from sklearn.metrics import f1_score, recall_score, confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, GridSearchCV\n",
    "\n",
    "from sktime.pipeline import make_pipeline\n",
    "\n",
    "from sktime.dists_kernels.dtw import DtwDtaidistMultiv\n",
    "from sktime.classification.distance_based import KNeighborsTimeSeriesClassifier\n",
    "\n",
    "from sktime.transformations.panel.rocket import MiniRocketMultivariate\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "#from sktime.classification.feature_based import FreshPRINCE\n",
    "from sktime.classification.interval_based import DrCIF\n",
    "#from sktime.classification.shapelet_based import ShapeletTransformClassifier\n",
    "from sktime.classification.dictionary_based import TemporalDictionaryEnsemble\n",
    "from sktime.classification.deep_learning import InceptionTimeClassifier\n",
    "#from sktime.classification.hybrid import HIVECOTEV2\n",
    "\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "machines = [\"M01\", \"M02\",\"M03\"]\n",
    "process_names = [\"OP00\",\"OP01\",\"OP02\",\"OP03\",\"OP04\",\"OP05\",\"OP06\",\"OP07\",\"OP08\",\"OP09\",\"OP10\",\"OP11\",\"OP12\",\"OP13\",\"OP14\"]\n",
    "labels = [\"good\",\"bad\"]\n",
    "path_to_dataset = Path(\"./data/\").absolute()\n",
    "\n",
    "split_functions = [machine_split, time_split, op_split] \n",
    "splits = [\"machine\", \"time\", \"operation\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_data = []\n",
    "y_data = []\n",
    "\n",
    "for process_name, machine, label in itertools.product(process_names, machines, labels):\n",
    "    data_path = os.path.join(path_to_dataset, machine, process_name, label)\n",
    "    data_list, data_label = data_loader_utils.load_tool_research_data(data_path, label=label, add_additional_label = True, verbose = False)\n",
    "    #concatenating\n",
    "    X_data.extend(data_list)\n",
    "    y_data.extend(data_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = [x.astype(np.float64) for x in X_data] # Ensure all examples have the same datatype\n",
    "X = np.array([x[:4096, :3] for x in X]) # Select the first 4096 timesteps of all three dimensions for each row\n",
    "y = np.array([0 if id.split(\"_\")[-1] == \"good\" else 1 for id in y_data])\n",
    "\n",
    "# Reshape X into a dataframe that is compatible with MiniRocket transform\n",
    "axis = [\"X-axis\", \"Y-axis\", \"Z-axis\"] \n",
    "axisdict = {\"X-axis\": [], \"Y-axis\":[],  \"Z-axis\":[]}\n",
    "for i, ax in enumerate(axis):\n",
    "    for n in range(X.shape[0]):\n",
    "        axisdict[ax].append(pd.Series(X[n][:,i]))\n",
    "\n",
    "X_df = pd.DataFrame(axisdict)\n",
    "\n",
    "a = [y.split(\"_\") for y in y_data]\n",
    "y_df = pd.DataFrame(a)\n",
    "df = X_df.join(y_df).rename(columns = {0: \"MC\", 1: \"MM\", 2: \"YY\", 3: \"OP\", 4: \"n\", 5: \"y\"})\n",
    "df[\"y\"] = df[\"y\"].apply(lambda x: 1 if x == \"bad\" else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cv_results(clf, param_grid, df = df, splits = splits, split_functions = split_functions):\n",
    "    cv_results = {}\n",
    "    gs_objects = {}\n",
    "    for i, split in enumerate(splits):\n",
    "        print(f\"Processing the {split}-wise split...\")\n",
    "        splitter = split_functions[i]\n",
    "        X_train, X_test, y_train, y_test = splitter(df)\n",
    "        gs = GridSearchCV(clf, \n",
    "                          param_grid, \n",
    "                          scoring = \"f1\", \n",
    "                          n_jobs = -1, \n",
    "                          cv = StratifiedKFold(n_splits = 3)\n",
    "                         )\n",
    "        gs.fit(X_train, y_train)\n",
    "\n",
    "        cv_results[split] = gs.cv_results_\n",
    "        gs_objects[split] = gs\n",
    "    return cv_results, gs_objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle \n",
    "\n",
    "with open('saved_dictionary.pkl', 'wb') as f:\n",
    "    pickle.dump(dictionary, f)\n",
    "        \n",
    "with open('saved_dictionary.pkl', 'rb') as f:\n",
    "    loaded_dict = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distance = DtwDtaidistMultiv(use_c = True)\n",
    "knn = KNeighborsTimeSeriesClassifier(n_neighbors = 1, distance = distance, n_jobs = -1)\n",
    "\n",
    "knn_f1 = []\n",
    "knn_recall = []\n",
    "\n",
    "for i, split in enumerate(splits):\n",
    "    print(f\"Processing {split}-wise split...\")\n",
    "    splitter = split_functions[i]\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = splitter(df)\n",
    "    knn.fit(X_train, y_train)\n",
    "    y_preds = knn.predict(X_test)\n",
    "    \n",
    "    knn_f1.append(f1_score(y_test, y_preds))\n",
    "    knn_recall.append(recall_score(y_test, y_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trf = MiniRocketMultivariate(n_jobs = 1) \n",
    "clf = LogisticRegression(solver = \"liblinear\", n_jobs = 1)\n",
    "        \n",
    "MiniRocketLR = make_pipeline(trf, clf)\n",
    "\n",
    "param_grid_MiniRocketLR = {\n",
    "    \"penalty\" : [\"l1\", \"l2\"],\n",
    "    'C': [0.01, 0.1, 1, 10, 100]\n",
    "}\n",
    "\n",
    "cv_results_MiniRocketLR, gs_objects_MiniRocketLR = get_cv_results(MiniRocketLR, param_grid_MiniRocketLR)\n",
    "\n",
    "import pickle \n",
    "with open(\"cv_results/MiniRocketLR.pkl\", \"wb\") as f:\n",
    "    pickle.dump(cv_results_MiniRocketLR, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drcif = DrCIF(n_jobs = -1)\n",
    "\n",
    "param_grid_drcif = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    \"att_subsample_size\": [5, 10, 20],       \n",
    "}\n",
    "\n",
    "cv_results_drcif, gs_objects_drcif = get_cv_results(drcif, param_grid_drcif)\n",
    "\n",
    "with open(\"cv_results/drdcif.pkl\", \"wb\") as f:\n",
    "    pickle.dump(cv_results_drcif, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tde = TemporalDictionaryEnsemble(n_jobs = -1)\n",
    "\n",
    "param_grid_tde = {\n",
    "    \"n_parameter_samples\" : [50, 250],\n",
    "    \"max_ensemble_size\" : [5, 50],\n",
    "    \"randomly_selected_params\" : [5, 50]\n",
    "}\n",
    "\n",
    "cv_results_tde, gs_objects_tde = get_cv_results(tde, param_grid_tde)\n",
    "\n",
    "with open(\"cv_results/tde.pkl\", \"wb\") as f: \n",
    "    pickle.dump(cv_results_tde, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "itc = InceptionTimeClassifier(n_epochs = 50, batch_size = 16)\n",
    "\n",
    "param_grid_itc = {\n",
    "    \"kernel_size\" : [10, 40],\n",
    "    \"n_filters\" : [6, 32],\n",
    "}\n",
    "\n",
    "cv_results_itc, gs_objects_itc = get_cv_results(itc, param_grid_itc)\n",
    "\n",
    "with open(\"cv_results/itc.pkl\", \"wb\") as f: \n",
    "    pickle.dump(cv_results_itc, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
